\documentclass[12pt]{article}
\usepackage{tikz}
\usetikzlibrary{trees}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,scrextend}
\usepackage{fancyhdr}
\setlength{\headheight}{14.5pt}
\addtolength{\topmargin}{-2.5pt}
\pagestyle{fancy}

\newcommand{\cont}{\subseteq}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{amsmath}
\usepackage[mathscr]{euscript}
\let\euscr\mathscr\let\mathscr\relax% just so we can load this and rsfs
\usepackage[scr]{rsfso}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{multicol}
\usepackage[colorlinks=true, pdfstartview=FitV, linkcolor=blue,
citecolor=blue, urlcolor=blue]{hyperref}

\DeclareMathOperator{\arcsec}{arcsec}
\DeclareMathOperator{\arccot}{arccot}
\DeclareMathOperator{\arccsc}{arccsc}
\newcommand{\ddx}{\frac{d}{dx}}
\newcommand{\dfdx}{\frac{df}{dx}}
\newcommand{\ddxp}[1]{\frac{d}{dx}\left( #1 \right)}
\newcommand{\dydx}{\frac{dy}{dx}}
\let\ds\displaystyle
\newcommand{\intx}[1]{\int #1 \, dx}
\newcommand{\intt}[1]{\int #1 \, dt}
\newcommand{\defint}[3]{\int_{#1}^{#2} #3 \, dx}
\newcommand{\imp}{\Rightarrow}
\newcommand{\un}{\cup}
\newcommand{\inter}{\cap}
\newcommand{\ps}{\mathscr{P}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newtheorem*{sol}{Solution}
\newtheorem*{claim}{Claim}
\newtheorem{problem}{Problem}
\pgfplotsset{compat=1.17}
\begin{document}
 
% Don't change the above session

\lhead{Financial Mathematics hw3}
\chead{111352027}
\rhead{\today}
%%\section*{Useful sets}
%%$\mathcal{F}_0 = \{\phi,\Omega\} \quad\ \mathcal{F}_1 = \{\{\omega_1, \omega_2, \omega_3\},\cdots, \Omega\}\quad\ \mathcal{F}_2 = \{\{\omega_1\},\cdots, \Omega\}\quad\ \mathcal{F}_3\ with\ 64\ items$\\
%%$A = \{\omega_1, \omega_4\}\quad\ B = \{\omega_1, \omega_2, \omega_3\}\quad\ C = \{\omega_3, \omega_4, \omega_5\}$\\\\
%%\begin{align*}
%%    align
%%\end{align*}
% \maketitle
\section{Multiple Linear Equation}
Proof
\[
    \min_{\alpha,\ \beta_i} E[(Y-\alpha-\beta_1 X_1 - \cdots - \beta_n X_n)^2]\Rightarrow \begin{cases}
        \hat{\alpha} & = E(Y) - \sum_{i=1}^n \beta_i X_i\\
        \hat{\beta} & = Var(X)^{-1}Cov(X,Y)
    \end{cases}  
\]
To minimize $E[(Y-\alpha-\beta_1 X_1 - \cdots - \beta_n X_n)^2]$, we need to get the first order condition of $\alpha$
\begin{align*}
    \hat{\alpha} & : E(Y-\hat{\alpha} - \hat{\beta_1} X_1 -\cdots - \hat{\beta_n} X_n) = 0\\
    \hat{\alpha} & = E(Y) - E(\hat{\beta_1} X_1 - \cdots - \hat{\beta_n} X_n) \\
    \hat{\alpha} & = E(Y) - \sum_{i=1}^n \hat{\beta_i} E(X_i)
\end{align*}
\begin{align*}
    Cov(\mathbbm{X},Y) &= Cov(\mathbbm{X}, \alpha+\beta \mathbbm{X}) = Cov(\mathbbm{X}, \beta \mathbbm{X}) = \beta Cov(\mathbb{X}, \mathbbm{X}) = \beta Var(\mathbbm{X})\\
    \Rightarrow \hat{\beta} &= Var(\mathbbm{X})^{-1}Cov(\mathbbm{X}, Y)
\end{align*}
\section{Radon Nikodym Derivative}
\subsection*{Proof}
\[\dfrac{dQ}{dP}\ exists \Rightarrow P >> Q\] \\
$P >> Q$ means that $P$ dominates $Q$, if and only if $Q$ is absolutely continuous $w.r.t$ $P$.
\begin{align*}
    Q(B) = \int_B \dfrac{dQ}{dP}dP
\end{align*}
If we assume $P(B)=0$, we know that $dP=0$
\begin{align*}
    Q(B) = \int_B \dfrac{dQ}{dP}dP = \int_B 0 = 0  
\end{align*}
So we can conclude that if $\dfrac{dQ}{dP}$ exists, then $P(B) = 0 \Rightarrow Q(B)=0(P >> Q)$
\section{Explain Equation}
Because $\xi = \dfrac{dQ}{dP}$, $dQ = \xi dP$
\begin{align*}
    \int_G\dfrac{E_p(\xi X|\mathcal{G})}{E_p(\xi|\mathcal{G})}dQ = \int_G\dfrac{E_p(\xi X|\mathcal{G})}{E_p(\xi|\mathcal{G})}\xi dP
\end{align*}
According to Law of Iterated Expectation (L.I.E), we know that
\begin{align*}
    \int_G\dfrac{E_p(\xi X|\mathcal{G})}{E_p(\xi|\mathcal{G})}\xi dP = \int_G E_p\Bigg[\dfrac{E_p (\xi X|\mathcal{G})}{E_p (\xi |\mathcal{G})}\xi \Bigg|\mathcal{G}\Bigg]dP
\end{align*}
Because $\dfrac{E_p (\xi X|\mathcal{G})}{E_p (\xi|\mathcal{G})}$ is a constant, we can conclude that
\begin{align*} 
    \int_G E_p\Bigg[\dfrac{E_p (\xi X|\mathcal{G})}{E_p (\xi |\mathcal{G})}\xi \Bigg|\mathcal{G}\Bigg]dP = \int_G \dfrac{E_p (\xi X|\mathcal{G})}{E_p(\xi|\mathcal{G})}E_p(\xi|\mathcal{G})dP = \int_G E_p(\xi X|\mathcal{G})dP
\end{align*}
Thus, we know that $X$ is $\mathcal{G}$ measurable and intergral random variable, So
\begin{align*}
    \int_G E_p(\xi X |\mathcal{G})dP = \int_G X \xi dP = \int_G X dQ
\end{align*}
\end{document}